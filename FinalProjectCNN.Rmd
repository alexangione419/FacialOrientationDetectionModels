---
title: "FinalProjectImageProcessing"
output: html_document
date: "2025-04-07"
---

```{r}

#library(torch)
#library(torchvision)
#install.packages("keras") 

library(tensorflow)
##library(keras3) 
#library(keras)


#install.packages("remotes")
#remotes::install_github("rstudio/tensorflow")
#install_tensorflow(version = "2.0.0b1", method = "conda", envname = "r-reticulate")

#remotes::install_github("rstudio/keras", dependencies = TRUE)
library(keras)


#install.packages("keras3")
#library(reticulate)
# install_keras(method = "conda", envname = "r-keras")
#install_tensorflow(method= "conda", envname= "t-flow")


#reticulate::install_miniconda()
#  conda_install(envname = "r-keras", packages = "keras", channel = "conda-forge")
#conda_install(envname = "r-keras", packages = "tensorflow", channel = "conda-forge")
##use_condaenv("r-keras", required = TRUE)
#library(reticulate)
#py_config()
```


```{r}
# data preparation

train_dir <- "./classifiedTrainingData"  
batch_size = 64

# Create a dataset 
train_ds <- image_dataset_from_directory(
  directory = train_dir,
  labels = "inferred",
  label_mode = "binary",       
  batch_size = batch_size,
  image_size = c(150, 150),    
  shuffle = TRUE
)



```


```{r}

# keras CNN

cnn_model <- keras_model_sequential()


cnn_model %>%
  #layer 1
  layer_conv_2d(filters = 32, kernel_size = c(5,5), activation = 'relu', input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  
  #layer 2
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  #dropout for over fitting avoidance 

  layer_flatten() %>% 
  #layer 3
  layer_dense(units = 256, activation = 'relu') %>% 
  #dropout for over fitting avoidance 
  layer_dropout(rate = 0.5) %>% 
  
  #layer 4 ??
  layer_dense(units = 128, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 

  # output layer
  layer_dense(units = 1, activation = 'sigmoid')




cnn_model %>% compile(
  optimizer = optimizer_adam(),
  loss = loss_binary_crossentropy,
  metrics = 'accuracy'
)

#cnn_model %>% compile(
#  loss = loss_categorical_crossentropy,
#  optimizer = optimizer_adadelta(),
#  metrics = c('accuracy')
#)

summary(cnn_model)
```




``` {r}
test_ds <- image_dataset_from_directory(
  directory = "./classifiedTestingData",  
  labels = "inferred",
  label_mode = "binary",          
  image_size = c(150, 150),
  shuffle = FALSE
)


```


``` {r}

cnn_history <- cnn_model %>% fit(
  train_ds,
  epochs = as.integer(30),
  validation_data = test_ds
)

print(cnn_history)

```




```{r}
library(ggplot2)

epochs <- 1:length(cnn_history$metrics$accuracy)

# Plot training accuracy (blue line)
plot(epochs, cnn_history$metrics$accuracy, type = "l", col = "blue",
     xlab = "Epoch", ylab = "Accuracy", lwd = 2,
     main = "Training vs Validation Accuracy")

# Add testing (validation) accuracy (red line)
lines(epochs, cnn_history$metrics$val_accuracy, type = "l", col = "orange", lwd = 2)


```


```{r}
# produce kernel visual
img_path <- "./data/lfw-deepfunneled/lfw-deepfunneled/Albrecht_Mentz_0002.jpg"  

image <- image_to_array(image_load(img_path, target_size = c(150, 150)))


image <- array_reshape(image, c(1, dim(image)))

activation_model <- keras_model(inputs = cnn_model$input,
                                outputs = cnn_model$layers[[1]]$output)

activation <- predict(activation_model, image)
activation_fix <- activation[1,,,]
filter_index <- 1
activation_map <- activation_fix[,, filter_index]

image(activation_map, 
      col = gray.colors(256), 
      axes = FALSE, 
      main = paste("Activation Map for Filter", filter_index))



```

