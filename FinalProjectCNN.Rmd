---
title: "FinalProjectImageProcessing"
output: html_document
date: "2025-04-07"
---

```{r}

max_pool <- function(X, pool_size) {
  m <- nrow(X)
  n <- ncol(X)
  
  # calculate dimensions of the pooled output
  pooled_height <- m - pool_size + 1
  pooled_width <- n - pool_size + 1
  pooled_output <- matrix(0, nrow = pooled_height, ncol = pooled_width)
  
  #pooling step
  for (i in 1:pooled_height) {
    for (j in 1:pooled_width) {
      pool_region <- G[i:(i + pool_size - 1), j:(j + pool_size - 1)]
      pooled_output[i, j] <- max(pool_region)
    }
  }
  
  return(pooled_output)
}

```


```{r setup, include=FALSE}

W <- matrix(c(-1, 0, 1,
              -1, 0, 1,
              -1, 0, 1), nrow = 3, byrow = TRUE)

# convolution layer function
convLayer <- function(X, W, stride=1) {
  # get the dimensions of the kernel and input
  k_dim <- nrow(W)
  x_dim <- nrow(X)
  
  # calculate the dimensions of the output matrix
  q <- (x_dim - k_dim) %/% stride + 1
  G <- matrix(0, nrow = q, ncol = q)
  
  # do the thing
  for (m in 1:q) {
    for (n in 1:q) {
      submatrix <- X[((m-1)*stride+1):((m-1)*stride+k_dim), ((n-1)*stride+1):((n-1)*stride+k_dim)]
      G[m, n] <- sum(W * submatrix)
    }
  }
  
  return(G)
}

```

```{r}

#library(torch)
#library(torchvision)
#install.packages("keras3") 

library(keras3) 
```


```{r}
# data preparation

# Define the path to your training data folder
train_dir <- "/home/alexangione/NUCode/ML2/project/classifiedData"  # Update with your actual path

# Create a data generator that rescales the pixel values
train_ds <- image_dataset_from_directory(
  directory = train_dir,
  labels = "inferred",
  label_mode = "binary",       # For two classes (or "categorical" for >2 classes)
  batch_size = 32,
  image_size = c(150, 150),     # Resize images to 150x150 pixels
  shuffle = TRUE
)



```


```{r}

# keras CNN
cnn_model <- keras_model_sequential()

cnn_model %>%
  layer_rescaling(scale = 1/255, input_shape = c(150, 150, 3)) %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu', input_shape = c(150, 150, 1)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  #layer_dropout(rate = 0.25) %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = 'relu') %>% 
  #layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 1, activation = 'sigmoid')

cnn_model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_sgd(),
  metrics = c("accuracy")
)


```


``` {r}

steps_per_epoch <- train_generator$samples %/% train_generator$batch_size

# Train your model using fit_generator. You can also provide a validation generator
# if you have one (e.g., validation_generator), along with validation steps.
cnn_model %>% fit(
  x = train_ds,
  steps_per_epoch = steps_per_epoch,
  epochs = 15
)

history <- cnn_model %>% fit(train_ds, epochs=10)
# Optionally, you can view the training history.
print(history)

```










